---
title: "p8105_hw6_xy2719"
author: "Yao"
date: "2025-12-02"
output: github_document
---

Load key packages.

```{r message=FALSE}
library(tidyverse)
library(modelr)
library(p8105.datasets)
```

## Problem 1

Load data file.

```{r}
homi_raw =
  readr::read_csv("data/homicide-data.csv")
```

Clean data.

```{r warning=FALSE}
# Create a city_state variable and a binary variable. Omit cities don't report victim race.
homi_df =
  homi_raw |>
  mutate(
    city_state = str_c(city, ", ", state),
    resolved = if_else(disposition == "Closed by arrest", 1, 0),
    victim_age = as.numeric(victim_age)
  ) |>
  filter(
    !city_state %in% c("Dallas, TX",
                       "Phoenix, AZ",
                       "Kansas City, MO",
                       "Tulsa, AL"),
    victim_race %in% c("White", "Black"),
    !is.na(victim_age),
    victim_sex %in% c("Male", "Female")
  ) |>
  mutate(
    victim_sex  = forcats::fct_relevel(victim_sex,  "Female"),
    victim_race = forcats::fct_relevel(victim_race, "White")
  )
```

Fit a logistic regression to Baltimore, MD.

```{r}
baltimore_df = 
  homi_df |>
  filter(city_state == "Baltimore, MD")

baltimore_glm = 
  glm(
    resolved ~ victim_age + victim_sex + victim_race,
    data   = baltimore_df,
    family = binomial()
  )

baltimore_or = 
  baltimore_glm |>
  broom::tidy(exponentiate = TRUE, conf.int = TRUE) |>
  filter(term == "victim_sexMale") |>
  select(term, estimate, conf.low, conf.high)

baltimore_or
```

Run glm for each of the cities.

```{r}
# Create logistic model function
log_reg = function(df) {
  glm(
    resolved ~ victim_age + victim_sex + victim_race,
    data   = df,
    family = binomial()
  )
}

# Fit function to each of the cities
city_or = 
  homi_df |>
  group_by(city_state) |>
  nest() |>
  mutate(
    fit = map(data, log_reg),
    tidy_fit = purrr::map(
      fit, 
      ~ broom::tidy(.x, exponentiate = TRUE, conf.int = TRUE)
    )
  ) |>
  select(city_state, tidy_fit) |>
  unnest(tidy_fit) |>
  filter(term == "victim_sexMale") |>
  ungroup() |>
  mutate(
    city_state = forcats::fct_reorder(city_state, estimate)
  )

# Dataframe with estimated ORs and CIs for each city
city_or_df =
  city_or |> 
  select(city_state, estimate, conf.low, conf.high) |> 
  arrange(estimate)

city_or_df
```

Plot shows the estimated ORs and CIs for each city.

```{r}
city_or_plot = 
  city_or |>
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point(size = 1.5) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(
    x = NULL,
    y = "Adjusted odds ratio (Male vs Female)",
    title = "Adjusted odds of a homicide being solved: male vs female victims"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.y  = element_text(size = 6.5)
    )

city_or_plot
```

```{r}
ggsave("figs/problem1.jpg", city_or_plot, width = 6.5, height = 5, dpi = 300)
```

Comments:

Cities are ordered from lowest to highest adjusted OR. Across the 47 cities, the adjusted odds ratios comparing male to female victims are below 1 in most cities, meaning homicides with male victims have lower odds of being solved than those with female victims after adjusting for victim age and race. It indicates that homicides with male victims are less likely to be solved than those with female victims. A few cities have ORs near or above 1, but many of those have wide confidence intervals that include 1, suggesting a lot of uncertainty.

## Problem 2

Load and clean data.

```{r}
set.seed(1)

data("weather_df")

weather_df =
  weather_df |>
  drop_na(tmax, tmin, prcp)
```

Define a function.

```{r}
boot_stats = function(df) {
  fit = lm(tmax ~ tmin + prcp, data = df)
  
  g = broom::glance(fit)
  t = broom::tidy(fit)
  
  beta_tmin = t |> 
    filter(term == "tmin") |> 
    pull(estimate)
  beta_prcp = t |> 
    filter(term == "prcp") |> 
    pull(estimate)
  
  tibble(
    r_squared  = g$r.squared,
    beta_ratio = beta_tmin / beta_prcp
  )
}
```

Use 5000 bootstrap samples.

```{r}
boot_results =
  weather_df |>
  bootstrap(n = 5000) |>
  mutate(stats = map(strap, boot_stats)) |>
  unnest(stats)
```

Plot distribution of estimates.

```{r}
boot_plot =
  boot_results |>
  pivot_longer(
    c(r_squared, beta_ratio),
    names_to = "parameter",
    values_to = "estimate"
  ) |>
  ggplot(aes(x = estimate)) +
  geom_histogram(bins = 40) +
  facet_wrap(~ parameter, scales = "free_x") +
  labs(
    x = "Bootstrap estimate",
    y = "Count",
    title = "Bootstrap distributions for r_squared and beta_tmin / beta_prcp"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
    
boot_plot
```

```{r}
ggsave("figs/problem2.jpg", boot_plot, width = 5.5)
```

Description:

The bootstrap histograms show the sampling distributions of both r_squared and the coefficient ratio beta_tmin / beta_prcp and based on 5000 resamples of the weather data.

The distribution of r_squared is tightly concentrated, indicating that the linear model consistently explains a large proportion of the variation in daily maximum temperature. The histogram is approximately unimodal and narrow, suggesting that the estimate of model fit is very stable across bootstrap samples.

In contrast, the distribution of the coefficient ratio beta_tmin / beta_prcp is much more dispersed and shows greater variability. This reflects the fact that the estimated effect of precipitation on maximum temperature is small, leading to instability when dividing by a coefficient close to zero. As a result, the ratio exhibits a wider and more skewed distribution.

Identify the 2.5% and 97.5% quantiles.

```{r}
boot_results |>
  summarise(
    r2_low     = quantile(r_squared, 0.025),
    r2_high    = quantile(r_squared, 0.975),
    ratio_low  = quantile(beta_ratio, 0.025),
    ratio_high = quantile(beta_ratio, 0.975)
  )
```

## Problem 3

Load and clean data.

```{r}
set.seed(2)

birthweight =
  read_csv("data/birthweight.csv") |> view()

# Check for NAs
birthweight |>
  summarise(across(everything(), ~ sum(is.na(.))))

# Convert numeric to factor
birth_df = 
  birthweight |>
  mutate(
    babysex = factor(babysex, levels = c(1, 2),
                     labels = c("Male", "Female")),
    frace   = factor(frace,
                     levels = c(1, 2, 3, 4, 8, 9),
                     labels = c("White", "Black", "Asian",
                                "PuertoRican", "Other", "Unknown")),
    malform = factor(malform, levels = c(0, 1),
                     labels = c("Absent", "Present")),
    mrace   = factor(mrace,
                     levels = c(1, 2, 3, 4, 8),
                     labels = c("White", "Black", "Asian",
                                "PuertoRican", "Other"))
  )
```

Regression model for birthweight.

```{r}
bw_model = 
  lm(
    bwt ~ gaweeks + blength + bhead + 
      babysex + mrace + momage + 
      ppbmi + smoken + wtgain + parity, 
    data = birth_df
  )

summary(bw_model)
```

Plot of model.

```{r}
res_fit_plot =
  birth_df |>
  add_predictions(bw_model) |>
  add_residuals(bw_model) |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  labs(
    x = "Fitted values",
    y = "Residuals",
    title = "Residuals vs fitted values for birthweight model"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

res_fit_plot
```

```{r}
ggsave("figs/problem3.jpg", res_fit_plot, width = 5.5)
```

Description of modeling process:

I selected predictors for birthweight based on known clinical factors that influence fetal growth. Variables reflecting the baby’s size (length, head circumference), gestational age, maternal characteristics (age, BMI, weight gain, parity), smoking during pregnancy, and basic demographics (sex, mother’s race) were included because they have clear biological or empirical links to birthweight. I fit a linear regression using these predictors and then assessed model assumptions by plotting residuals versus fitted values using add_predictions() and add_residuals(), confirming that residuals were approximately centered with no major patterns.

Compare my model to two others.

```{r}
# Define the three functions
model_mine <- function(df) lm(
  bwt ~ gaweeks + blength + bhead +
    babysex + mrace +
    momage + ppbmi + smoken + wtgain + parity,
  data = df
)

model_len_gaw <- function(df) lm(
  bwt ~ blength + gaweeks,
  data = df
)

model_head_len_sex <- function(df) lm(
  bwt ~ bhead * blength * babysex,
  data = df
)

# RMSE function
rmse <- function(model, data) {
  preds <- predict(model, newdata = data)
  sqrt(mean((data$bwt - preds)^2))
}
```

Cross-validation prediction error

```{r}
set.seed(3)

cv_df =
  crossv_mc(birth_df, n = 100, test = 0.2)

cv_results =
  cv_df |>
  mutate(
    train = map(train, as_tibble),
    test = map(test,  as_tibble),
    
    fit_mine = map(train, model_mine),
    fit_len_gaw = map(train, model_len_gaw),
    fit_head_len_sex = map(train, model_head_len_sex),
    
    rmse_mine = map2_dbl(fit_mine, test, rmse),
    rmse_len_gaw = map2_dbl(fit_len_gaw, test, rmse),
    rmse_head_len_sex = map2_dbl(fit_head_len_sex, test, rmse)
  )
```

```{r}
 cv_results |>
  summarise(
    mean_rmse_mine         = mean(rmse_mine),
    mean_rmse_len_gaw      = mean(rmse_len_gaw),
    mean_rmse_head_len_sex = mean(rmse_head_len_sex)
  )
```

Using cross-validation, the proposed multivariable model had the lowest mean RMSE, indicating better out-of-sample prediction of birthweight than the simpler length + gestational age model and the three-way interaction model. The interaction model tended to have larger and more variable RMSE, likely reflecting overfitting due to its greater complexity.